import streamlit as st
import requests

import tiktoken

def count_tokens(text: str, model: str = "gpt-4o") -> int:
    try:
        enc = tiktoken.encoding_for_model(model)
    except:
        enc = tiktoken.get_encoding("cl100k_base")  # fallback
    return len(enc.encode(text))

st.set_page_config(page_title="MCP ê²€ìƒ‰ + GPT ì‘ë‹µ", layout="centered")

st.title("ğŸ” MCP Server ê¸°ë°˜ ê²€ìƒ‰ + GPT ì‘ë‹µ")

# ì…ë ¥ í¼
with st.form("mcp_form"):
    query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”?")
    openai_key = st.text_input("OpenAI API Key", type="password")
    serper_key = st.text_input("Serper API Key", type="password")
    submit = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")

if submit:
    if not all([query, openai_key, serper_key]):
        st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("MCP Serverì— ìš”ì²­ ì¤‘..."):
            try:
                response = requests.post(
                    "http://localhost:8000/mcp",
                    headers={
                        "X-OpenAI-API-Key": openai_key,
                        "X-Serper-API-Key": serper_key
                    },
                    json={"query": query},
                    timeout=30
                )
                response.raise_for_status()
                result = response.json()

                st.success("âœ… ìš”ì²­ ì„±ê³µ!")

                st.subheader("ğŸ“š ìš”ì•½ëœ ê²€ìƒ‰ ê²°ê³¼")
                st.markdown(result["context"])

                # ì‘ë‹µ í…ìŠ¤íŠ¸
                gpt_answer = result["final_answer"]

                st.subheader("ğŸ’¬ GPT ì‘ë‹µ")
                st.markdown(gpt_answer)                

                # í† í° ìˆ˜ ê³„ì‚°
                token_count = count_tokens(gpt_answer, model="gpt-4o")

                st.subheader("ğŸ“Š ì‘ë‹µ í† í° ìˆ˜")
                st.markdown(f"ì´ **{token_count} tokens**")

                # ì‹œê°ì  í‘œì‹œ (progress bar ê¸°ì¤€: 4096 = GPT-4o context ì˜ˆì‹œ)
                max_token = 8192  # gpt-4o ê¸°ì¤€ ì´ context limit
                st.progress(min(token_count, max_token) / max_token)

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
